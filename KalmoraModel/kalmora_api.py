# -*- coding: utf-8 -*-
"""Kalmora API.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u0zTALwboc2FcGNcF0oi9f24Y5aN4IK0
"""

from google.colab import files
uploaded = files.upload()

import shutil
import os

if not os.path.exists("saved_model"):
    os.makedirs("saved_model")

shutil.unpack_archive("saved_model.zip", "saved_model")

pip install flask flask-cors pyngrok librosa transformers torch numpy soundfile

from pyngrok import ngrok
ngrok.set_auth_token("2tHraDllyVVvqEf1P7eTYCn0gbL_3czbS5rNuXmWwYPKSCYSz")

from flask import Flask, request, jsonify
import torch
import librosa
import numpy as np
import os
import json
from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor
from flask_cors import CORS
from pyngrok import ngrok

app = Flask(__name__)
CORS(app)

# Configure upload folder
UPLOAD_FOLDER = "uploads"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Load your Kalmora model and processor
model_path = "./saved_model"  # Path to your saved model
model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path)
processor = Wav2Vec2Processor.from_pretrained(model_path)

# Load label map from saved model
try:
    with open(os.path.join(model_path, 'label_map.json'), 'r') as f:
        inverse_label_map = json.load(f)
    # Convert string keys to integers (JSON converts all keys to strings)
    inverse_label_map = {int(k): v for k, v in inverse_label_map.items()}
except FileNotFoundError:
    # Fallback to hardcoded map if file doesn't exist
    inverse_label_map = {
        0: 'ps',
        1: 'angry',
        2: 'happy',
        3: 'sad',
        4: 'fear',
        5: 'disgust',
        6: 'neutral'
    }

# Move model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

def predict_emotion(file_path):
    try:
        # Load audio file
        speech, sr = librosa.load(file_path, sr=16000)

        # Pad/truncate to 32000 samples (2 seconds at 16kHz)
        max_length = 32000
        if len(speech) > max_length:
            speech = speech[:max_length]
        else:
            speech = np.pad(speech, (0, max_length - len(speech)), mode='constant')

        # Process audio
        inputs = processor(
            speech,
            sampling_rate=16000,
            return_tensors="pt",
            padding=True
        ).to(device)

        # Predict
        with torch.no_grad():
            outputs = model(**inputs)
            predicted_class = outputs.logits.argmax().item()

        return {
            'emotion': inverse_label_map[predicted_class],
            'emotion_id': predicted_class
        }

    except Exception as e:
        print(f"Error processing file {file_path}: {str(e)}")
        return {"error": str(e)}

@app.route("/predict", methods=["POST"])
def predict():
    if "audio" not in request.files:
        return jsonify({"error": "No audio file provided"}), 400

    file = request.files["audio"]
    if file.filename == "":
        return jsonify({"error": "Empty filename"}), 400

    try:
        # Save temporarily
        file_path = os.path.join(UPLOAD_FOLDER, file.filename)
        file.save(file_path)

        # Predict emotion
        result = predict_emotion(file_path)

        # Clean up
        os.remove(file_path)

        if "error" in result:
            return jsonify({"error": result["error"]}), 500

        return jsonify({
            "predictions": [{
                "filename": file.filename,
                "emotion": result["emotion"],
                "emotion_id": result["emotion_id"]
            }]
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/", methods=["GET"])
def home():
    return """
    <html>
        <head>
            <title>Kalmora Emotion Recognition API</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; line-height: 1.6; }
                h1 { color: #333; }
                pre { background: #f4f4f4; padding: 15px; border-radius: 5px; }
            </style>
        </head>
        <body>
            <h1>Kalmora Speech Emotion Recognition API</h1>
            <p>Upload an audio file to the /predict endpoint to get emotion predictions.</p>
            <h2>Example curl command:</h2>
            <pre>curl -X POST -F "audio=@your-audio-file.wav" {request.host_url}predict</pre>
            <h2>Available emotions:</h2>
            <ul>
                <li>ps (Pleasant Surprise)</li>
                <li>angry</li>
                <li>happy</li>
                <li>sad</li>
                <li>fear</li>
                <li>disgust</li>
                <li>neutral</li>
            </ul>
        </body>
    </html>
    """

if __name__ == "__main__":

    port = 5000
    public_url = ngrok.connect(port).public_url
    print(f" * Running on {public_url}")
    print(f" * Local URL: http://localhost:{port}")

    # Run Flask app
    app.run(port=port)